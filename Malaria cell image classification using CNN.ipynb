{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a67f0b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f49b36c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 150\n",
    "def data_prepocessing(path):\n",
    "    images = []\n",
    "    file_list = os.listdir(path)\n",
    "    for file_name in file_list:\n",
    "        if file_name.endswith('.png'):\n",
    "            img_path = os.path.join(path,file_name)\n",
    "            img = cv2.imread(img_path)\n",
    "            img_RGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            resized_img = cv2.resize(img_RGB,(size,size))\n",
    "            #norm_resized_img = resized_img.astype('float32') / 255.0\n",
    "            images.append(resized_img)\n",
    "    return np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff841ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "infected_images = data_prepocessing(\"E:\\\\Masters\\\\Semester 4\\\\Malaria Detection\\\\archive\\\\cell_images\\\\Parasitized\")\n",
    "noninfected_images= data_prepocessing(\"E:\\\\Masters\\\\Semester 4\\\\Malaria Detection\\\\archive\\\\cell_images\\\\Uninfected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7388194e",
   "metadata": {},
   "outputs": [],
   "source": [
    "infected_labels = np.ones(len(infected_images))\n",
    "noninfected_labels = np.zeros(len(noninfected_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb8a7679",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate((infected_images, noninfected_images))\n",
    "y = np.concatenate((infected_labels, noninfected_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "682ab865",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e0ce9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import normalize\n",
    "X_train = normalize(X_train, axis=1)\n",
    "X_test = normalize(X_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5d0c133",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = (size, size, 3)   #change to (SIZE, SIZE, 3)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=INPUT_SHAPE))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), kernel_initializer = 'he_uniform'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), kernel_initializer = 'he_uniform'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6cdada8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "758a430c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 148, 148, 32)      0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 74, 74, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 72, 72, 32)        9248      \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 72, 72, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 36, 36, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 34, 34, 64)        18496     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 34, 34, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 17, 17, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 18496)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                1183808   \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 64)                0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,212,513\n",
      "Trainable params: 1,212,513\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51cc0728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "314/314 [==============================] - 162s 509ms/step - loss: 0.6330 - accuracy: 0.6489\n",
      "Epoch 2/5\n",
      "314/314 [==============================] - 160s 509ms/step - loss: 0.2537 - accuracy: 0.9236\n",
      "Epoch 3/5\n",
      "314/314 [==============================] - 156s 497ms/step - loss: 0.2121 - accuracy: 0.9451\n",
      "Epoch 4/5\n",
      "314/314 [==============================] - 151s 481ms/step - loss: 0.1840 - accuracy: 0.9492\n",
      "Epoch 5/5\n",
      "314/314 [==============================] - 151s 480ms/step - loss: 0.1632 - accuracy: 0.9506\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, \n",
    "                         y_train, \n",
    "                         batch_size = 64,\n",
    "                         epochs = 5,\n",
    "                         shuffle = False\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3409aad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 10s 56ms/step\n",
      "Precision:  0.9586206896551724\n",
      "Recall:  0.9548083875632682\n"
     ]
    }
   ],
   "source": [
    "outputs= model.predict(X_test)\n",
    "binary_predictions = (outputs > 0.5).astype(int)\n",
    "\n",
    "precision = precision_score(y_test, binary_predictions)\n",
    "recall = recall_score(y_test, binary_predictions)\n",
    "\n",
    "\n",
    "\n",
    "print('Precision: ',precision)\n",
    "print('Recall: ',recall)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c25cc53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9524093986459577\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, binary_predictions)  # Calculate accuracy\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1dc48ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 9s 53ms/step - loss: 0.1550 - accuracy: 0.9524\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "434f848b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.1550319939851761\n",
      "Validation accuracy: 0.9524093866348267\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation loss:\", loss)\n",
    "print(\"Validation accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df6fe923",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = X_test[0]\n",
    "\n",
    "input_img = np.expand_dims(img, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db254605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step\n",
      "predicted label =  [[0.99998784]]\n",
      "actual label =  1.0\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(input_img)\n",
    "print('predicted label = ', pred)\n",
    "print('actual label = ',y_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bef8be",
   "metadata": {},
   "source": [
    "\n",
    "# ResNet 50:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ef285b",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7465131d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 224\n",
    "def data_prepocessing(path):\n",
    "    images = []\n",
    "    file_list = os.listdir(path)\n",
    "    for file_name in file_list:\n",
    "        if file_name.endswith('.png'):\n",
    "            img_path = os.path.join(path,file_name)\n",
    "            img = cv2.imread(img_path)\n",
    "            img_RGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            resized_img = cv2.resize(img_RGB,(SIZE,SIZE))\n",
    "            #norm_resized_img = resized_img.astype('float32') / 255.0\n",
    "            images.append(resized_img)\n",
    "    return np.array(images)\n",
    "\n",
    "\n",
    "infected_images = data_prepocessing(\"E:\\\\Masters\\\\Semester 4\\\\Malaria Detection\\\\archive\\\\cell_images\\\\Parasitized\")\n",
    "noninfected_images= data_prepocessing(\"E:\\\\Masters\\\\Semester 4\\\\Malaria Detection\\\\archive\\\\cell_images\\\\Uninfected\")\n",
    "\n",
    "infected_labels = np.ones(len(infected_images))\n",
    "noninfected_labels = np.zeros(len(noninfected_images))\n",
    "\n",
    "X = np.concatenate((infected_images, noninfected_images))\n",
    "y = np.concatenate((infected_labels, noninfected_labels))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825d820a",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 22.5 GiB for an array with shape (20088, 224, 224, 3) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [35], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m normalize\n\u001b[1;32m----> 2\u001b[0m X_train \u001b[38;5;241m=\u001b[39m \u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m X_test \u001b[38;5;241m=\u001b[39m normalize(X_test, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\np_utils.py:91\u001b[0m, in \u001b[0;36mnormalize\u001b[1;34m(x, axis, order)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;129m@keras_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.utils.normalize\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnormalize\u001b[39m(x, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;124;03m\"\"\"Normalizes a Numpy array.\u001b[39;00m\n\u001b[0;32m     82\u001b[0m \n\u001b[0;32m     83\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;124;03m        A normalized copy of the array.\u001b[39;00m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 91\u001b[0m     l2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39matleast_1d(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     92\u001b[0m     l2[l2 \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(l2, axis)\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mnorm\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\linalg\\linalg.py:2511\u001b[0m, in \u001b[0;36mnorm\u001b[1;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[0;32m   2508\u001b[0m x \u001b[38;5;241m=\u001b[39m asarray(x)\n\u001b[0;32m   2510\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(x\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, (inexact, object_)):\n\u001b[1;32m-> 2511\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2513\u001b[0m \u001b[38;5;66;03m# Immediately handle some default, simple, fast, and common cases.\u001b[39;00m\n\u001b[0;32m   2514\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 22.5 GiB for an array with shape (20088, 224, 224, 3) and data type float64"
     ]
    }
   ],
   "source": [
    "from keras.utils import normalize\n",
    "X_train = normalize(X_train, axis=1)\n",
    "X_test = normalize(X_test, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e31da3",
   "metadata": {},
   "source": [
    "## Data preprocessing using DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b41a3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import random_split\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a6ba665d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#infected_images = data_prepocessing(\"E:\\\\Masters\\\\Semester 4\\\\Malaria Detection\\\\archive\\\\cell_images\\\\Parasitized\")\n",
    "#noninfected_images= data_prepocessing(\"E:\\\\Masters\\\\Semester 4\\\\Malaria Detection\\\\archive\\\\cell_images\\\\Uninfected\")\n",
    "\n",
    "mean = [0.4751, 0.4270, 0.3992]\n",
    "std = [0.3097, 0.3083, 0.3183] \n",
    "\n",
    "data_dir = \"E:\\\\Masters\\\\Semester 4\\\\Malaria Detection\\\\archive\\\\cell_images\"\n",
    "\n",
    "dataset = ImageFolder(data_dir,transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),transforms.ToTensor(),transforms.Normalize(mean,std)])) # Loading the data into the system\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb8baa69",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "val_size = int(0.2*len(dataset))\n",
    "train_size = len(dataset)- val_size\n",
    "train_data, val_data = random_split(dataset, [train_size, val_size])\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "valloader = torch.utils.data.DataLoader(val_data, batch_size=64,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a469bd78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ianme\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ianme\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] - Validation Loss: 0.2635, Accuracy: 90.48%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32me:\\Masters\\Semester 4\\Malaria Detection\\Malaria cell image classification using CNN.ipynb Cell 26\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Masters/Semester%204/Malaria%20Detection/Malaria%20cell%20image%20classification%20using%20CNN.ipynb#X34sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Masters/Semester%204/Malaria%20Detection/Malaria%20cell%20image%20classification%20using%20CNN.ipynb#X34sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     \u001b[39mfor\u001b[39;00m inputs, labels \u001b[39min\u001b[39;00m valloader:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/Masters/Semester%204/Malaria%20Detection/Malaria%20cell%20image%20classification%20using%20CNN.ipynb#X34sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m         outputs \u001b[39m=\u001b[39m resnet50(inputs)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Masters/Semester%204/Malaria%20Detection/Malaria%20cell%20image%20classification%20using%20CNN.ipynb#X34sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m         val_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m criterion(outputs, labels)\u001b[39m.\u001b[39mitem()\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Masters/Semester%204/Malaria%20Detection/Malaria%20cell%20image%20classification%20using%20CNN.ipynb#X34sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m         _, predicted \u001b[39m=\u001b[39m outputs\u001b[39m.\u001b[39mmax(\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ianme\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\ianme\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 285\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward_impl(x)\n",
      "File \u001b[1;32mc:\\Users\\ianme\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\resnet.py:269\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_forward_impl\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m    267\u001b[0m     \u001b[39m# See note [TorchScript super()]\u001b[39;00m\n\u001b[0;32m    268\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv1(x)\n\u001b[1;32m--> 269\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbn1(x)\n\u001b[0;32m    270\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(x)\n\u001b[0;32m    271\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmaxpool(x)\n",
      "File \u001b[1;32mc:\\Users\\ianme\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\ianme\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:171\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    164\u001b[0m     bn_training \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_mean \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mand\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_var \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    166\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[39mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[0;32m    168\u001b[0m \u001b[39mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[0;32m    169\u001b[0m \u001b[39mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[0;32m    170\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 171\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mbatch_norm(\n\u001b[0;32m    172\u001b[0m     \u001b[39minput\u001b[39;49m,\n\u001b[0;32m    173\u001b[0m     \u001b[39m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunning_mean\n\u001b[0;32m    175\u001b[0m     \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrack_running_stats\n\u001b[0;32m    176\u001b[0m     \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    177\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunning_var \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrack_running_stats \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    178\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[0;32m    179\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias,\n\u001b[0;32m    180\u001b[0m     bn_training,\n\u001b[0;32m    181\u001b[0m     exponential_average_factor,\n\u001b[0;32m    182\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meps,\n\u001b[0;32m    183\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\ianme\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2450\u001b[0m, in \u001b[0;36mbatch_norm\u001b[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[0;32m   2447\u001b[0m \u001b[39mif\u001b[39;00m training:\n\u001b[0;32m   2448\u001b[0m     _verify_batch_size(\u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize())\n\u001b[1;32m-> 2450\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mbatch_norm(\n\u001b[0;32m   2451\u001b[0m     \u001b[39minput\u001b[39;49m, weight, bias, running_mean, running_var, training, momentum, eps, torch\u001b[39m.\u001b[39;49mbackends\u001b[39m.\u001b[39;49mcudnn\u001b[39m.\u001b[39;49menabled\n\u001b[0;32m   2452\u001b[0m )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load pre-trained ResNet-50\n",
    "resnet50 = models.resnet50(pretrained=True)\n",
    "\n",
    "# Freeze all layers except the last one\n",
    "for param in resnet50.parameters():\n",
    "    param.requires_grad = False\n",
    "num_classes = len(dataset.classes)\n",
    "resnet50.fc = nn.Linear(resnet50.fc.in_features, num_classes)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(resnet50.fc.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "resnet50.train()\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for inputs, labels in trainloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = resnet50(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Validation loop\n",
    "    resnet50.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in valloader:\n",
    "            outputs = resnet50(inputs)\n",
    "            val_loss += criterion(outputs, labels).item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] - Validation Loss: {val_loss/len(valloader):.4f}, Accuracy: {(correct/total)*100:.2f}%\")\n",
    "\n",
    "# After training loop is complete, you can save or use the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff7ecc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "# Load pre-trained ResNet-50\n",
    "resnet50 = models.resnet50(pretrained=True)\n",
    "\n",
    "# Freeze all layers except the last one\n",
    "for param in resnet50.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "num_classes = 1  # For binary classification\n",
    "resnet50.fc = nn.Linear(resnet50.fc.in_features, num_classes)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()  # Use BCEWithLogitsLoss for binary classification\n",
    "optimizer = torch.optim.SGD(resnet50.fc.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    resnet50.train()  # Set the model to training mode\n",
    "    for inputs, labels in trainloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = resnet50(inputs)\n",
    "        loss = criterion(outputs.view(-1), labels.float())  # BCEWithLogitsLoss expects float labels\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Validation loop\n",
    "    resnet50.eval()  # Set the model to evaluation mode\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in valloader:\n",
    "            labels = labels.view(-1, 1)\n",
    "            outputs = resnet50(inputs)\n",
    "            val_loss += criterion(outputs, labels.float()).item()  # BCEWithLogitsLoss expects float labels\n",
    "            predicted = (outputs > 0.0).float()  # Convert logits to binary predictions\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels.float()).sum().item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] - Validation Loss: {val_loss/len(valloader):.4f}, Accuracy: {(correct/total)*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade96354",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
